{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673d4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048b87a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>heartbeat_signals</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9912297987616655,0.9435330436439665,0.764677...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9714822034884503,0.9289687459588268,0.572932...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0,0.9591487564065292,0.7013782792997189,0.23...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9757952826275774,0.9340884687738161,0.659636...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0,0.055816398940721094,0.26129357194994196,0...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  heartbeat_signals  label\n",
       "0   0  0.9912297987616655,0.9435330436439665,0.764677...    0.0\n",
       "1   1  0.9714822034884503,0.9289687459588268,0.572932...    0.0\n",
       "2   2  1.0,0.9591487564065292,0.7013782792997189,0.23...    2.0\n",
       "3   3  0.9757952826275774,0.9340884687738161,0.659636...    0.0\n",
       "4   4  0.0,0.055816398940721094,0.26129357194994196,0...    2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4936e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    " \n",
    "\n",
    "# 步骤1: 数据预处理\n",
    "# 分割心跳信号序列为数值列表\n",
    "df['heartbeat_signals'] = df['heartbeat_signals'].apply(lambda x: [float(i) for i in x.split(',')])\n",
    "\n",
    "# 将列表转换为DataFrame的列\n",
    "max_length = max(df['heartbeat_signals'].apply(len))  # 找到最长序列的长度\n",
    "signals_df = pd.DataFrame(df['heartbeat_signals'].tolist()).fillna(0)  # 用0填充缺失值\n",
    "df = pd.concat([df, signals_df], axis=1)\n",
    "\n",
    "# 删除原始的heartbeat_signals列\n",
    "df = df.drop('heartbeat_signals', axis=1)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3e90f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991230</td>\n",
       "      <td>0.943533</td>\n",
       "      <td>0.764677</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.379632</td>\n",
       "      <td>0.190822</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.025995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971482</td>\n",
       "      <td>0.928969</td>\n",
       "      <td>0.572933</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>0.122962</td>\n",
       "      <td>0.132360</td>\n",
       "      <td>0.094392</td>\n",
       "      <td>0.089575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959149</td>\n",
       "      <td>0.701378</td>\n",
       "      <td>0.231778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080698</td>\n",
       "      <td>0.128376</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975795</td>\n",
       "      <td>0.934088</td>\n",
       "      <td>0.659637</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.237116</td>\n",
       "      <td>0.281445</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.261294</td>\n",
       "      <td>0.359847</td>\n",
       "      <td>0.433143</td>\n",
       "      <td>0.453698</td>\n",
       "      <td>0.499004</td>\n",
       "      <td>0.542796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label         0         1         2         3         4         5   \n",
       "0   0    0.0  0.991230  0.943533  0.764677  0.618571  0.379632  0.190822  \\\n",
       "1   1    0.0  0.971482  0.928969  0.572933  0.178457  0.122962  0.132360   \n",
       "2   2    2.0  1.000000  0.959149  0.701378  0.231778  0.000000  0.080698   \n",
       "3   3    0.0  0.975795  0.934088  0.659637  0.249921  0.237116  0.281445   \n",
       "4   4    2.0  0.000000  0.055816  0.261294  0.359847  0.433143  0.453698   \n",
       "\n",
       "          6         7  ...  195  196  197  198  199  200  201  202  203  204  \n",
       "0  0.040237  0.025995  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.094392  0.089575  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.128376  0.187448  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.249921  0.249921  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.499004  0.542796  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f79d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# 步骤3: 模型训练\n",
    "X = df.drop(['id', 'label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 使用SMOTE进行过采样处理类别不平衡，只对训练集进行处理\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f844a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abs-Sum Score: 0.047693560848185025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# 假设 X 和 y 已经准备好了，X 是特征矩阵，y 是目标变量\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "abs_sum_scores = []  # 存储每一折的评分\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_resampled, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_resampled, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 预测概率\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # 计算abs-sum\n",
    "    # 首先，我们需要将y_test转换为one-hot编码形式，以匹配y_pred_proba的格式\n",
    "    y_test_one_hot = np.zeros((y_test.size, y_pred_proba.shape[1]))\n",
    "    y_test_one_hot[np.arange(y_test.size), y_test.astype(int)] = 1\n",
    "    \n",
    "    abs_sum = np.abs(y_test_one_hot - y_pred_proba).sum() / y_test.size\n",
    "    abs_sum_scores.append(abs_sum)\n",
    "\n",
    "# 计算平均abs-sum分数\n",
    "average_abs_sum = np.mean(abs_sum_scores)\n",
    "print(f\"Average Abs-Sum Score: {average_abs_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89cd69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取CSV文件\n",
    "df1 = pd.read_csv(\"data/testA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6d12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# 假设 df 是包含上述数据的DataFrame\n",
    "\n",
    "# 步骤1: 数据预处理\n",
    "# 分割心跳信号序列为数值列表\n",
    "df1['heartbeat_signals'] = df1['heartbeat_signals'].apply(lambda x: [float(i) for i in x.split(',')])\n",
    "\n",
    "# 将列表转换为DataFrame的列\n",
    "max_length = max(df1['heartbeat_signals'].apply(len))  # 找到最长序列的长度\n",
    "signals_df = pd.DataFrame(df1['heartbeat_signals'].tolist()).fillna(0)  # 用0填充缺失值\n",
    "df1 = pd.concat([df1, signals_df], axis=1)\n",
    "\n",
    "# 删除原始的heartbeat_signals列\n",
    "df1 = df1.drop('heartbeat_signals', axis=1)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6a8d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.991571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631816</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>0.120854</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>0.107915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.541708</td>\n",
       "      <td>0.340694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090708</td>\n",
       "      <td>0.164924</td>\n",
       "      <td>0.195034</td>\n",
       "      <td>0.168838</td>\n",
       "      <td>0.198844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38996</td>\n",
       "      <td>0.386932</td>\n",
       "      <td>0.367251</td>\n",
       "      <td>0.363917</td>\n",
       "      <td>0.360574</td>\n",
       "      <td>0.357245</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.350565</td>\n",
       "      <td>0.363874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.975273</td>\n",
       "      <td>0.671097</td>\n",
       "      <td>0.686759</td>\n",
       "      <td>0.708482</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.720548</td>\n",
       "      <td>0.701656</td>\n",
       "      <td>0.596579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.917025</td>\n",
       "      <td>0.521096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221770</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.490399</td>\n",
       "      <td>0.527158</td>\n",
       "      <td>0.518056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887949</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.531720</td>\n",
       "      <td>0.380320</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         0         1         2         3         4         5   \n",
       "0  100000  0.991571  1.000000  0.631816  0.136230  0.041420  0.102707  \\\n",
       "1  100001  0.607553  0.541708  0.340694  0.000000  0.090708  0.164924   \n",
       "2  100002  0.975273  0.671097  0.686759  0.708482  0.718660  0.716763   \n",
       "3  100003  0.995635  0.917025  0.521096  0.000000  0.221770  0.404100   \n",
       "4  100004  1.000000  0.887949  0.745565  0.531720  0.380320  0.224631   \n",
       "\n",
       "          6         7         8  ...      195       196       197       198   \n",
       "0  0.120854  0.123428  0.107915  ...  0.00000  0.000000  0.000000  0.000000  \\\n",
       "1  0.195034  0.168838  0.198844  ...  0.38996  0.386932  0.367251  0.363917   \n",
       "2  0.720548  0.701656  0.596579  ...  0.00000  0.000000  0.000000  0.000000   \n",
       "3  0.490399  0.527158  0.518056  ...  0.00000  0.000000  0.000000  0.000000   \n",
       "4  0.091148  0.057639  0.003915  ...  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        199       200       201       202       203       204  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.360574  0.357245  0.350575  0.350575  0.350565  0.363874  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e756116e",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "\n",
    "\n",
    "# 提取ID列和特征列\n",
    "ids = df1['id']\n",
    "X_test = df1.drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6e1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你的模型是model\n",
    "y_pred_proba = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d23afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建结果DataFrame\n",
    "results_df = pd.DataFrame(y_pred_proba, columns=[f'label_{i}' for i in range(y_pred_proba.shape[1])])\n",
    "results_df.insert(0, 'id', ids)\n",
    "\n",
    "# 保存到CSV\n",
    "results_df.to_csv('data/prediction_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd6d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取CSV文件\n",
    "df2 = pd.read_csv(\"data/prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffdfd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.995096</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   label_0   label_1   label_2   label_3\n",
       "0  100000  0.999721  0.000258  0.000010  0.000011\n",
       "1  100001  0.001209  0.003688  0.995096  0.000007\n",
       "2  100002  0.000107  0.000011  0.000137  0.999744\n",
       "3  100003  0.999751  0.000151  0.000092  0.000006\n",
       "4  100004  0.999896  0.000042  0.000026  0.000036"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd30428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'label'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88cc2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52275\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 205\n",
      "[LightGBM] [Info] Start training from score -0.442350\n",
      "[LightGBM] [Info] Start training from score -3.342103\n",
      "[LightGBM] [Info] Start training from score -1.940114\n",
      "[LightGBM] [Info] Start training from score -1.723587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52270\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 205\n",
      "[LightGBM] [Info] Start training from score -0.440289\n",
      "[LightGBM] [Info] Start training from score -3.315593\n",
      "[LightGBM] [Info] Start training from score -1.958552\n",
      "[LightGBM] [Info] Start training from score -1.721627\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52274\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 205\n",
      "[LightGBM] [Info] Start training from score -0.442914\n",
      "[LightGBM] [Info] Start training from score -3.330506\n",
      "[LightGBM] [Info] Start training from score -1.947361\n",
      "[LightGBM] [Info] Start training from score -1.718068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52270\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 205\n",
      "[LightGBM] [Info] Start training from score -0.438990\n",
      "[LightGBM] [Info] Start training from score -3.338575\n",
      "[LightGBM] [Info] Start training from score -1.963082\n",
      "[LightGBM] [Info] Start training from score -1.718137\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52273\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 205\n",
      "[LightGBM] [Info] Start training from score -0.441416\n",
      "[LightGBM] [Info] Start training from score -3.347775\n",
      "[LightGBM] [Info] Start training from score -1.951048\n",
      "[LightGBM] [Info] Start training from score -1.717093\n",
      "Average Abs-Sum Score: 0.06074900971405635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 假设 X 和 y 已经准备好了，X 是特征矩阵，y 是目标变量\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "abs_sum_scores = []  # 存储每一折的评分\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # 创建LightGBM模型\n",
    "    model = lgb.LGBMClassifier(objective='multiclass', num_class=len(np.unique(y)), metric='multi_logloss', random_state=42)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "    \n",
    "    # 预测概率\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # 计算abs-sum\n",
    "    y_test_one_hot = np.zeros((y_test.size, y_pred_proba.shape[1]))\n",
    "    y_test_one_hot[np.arange(y_test.size), y_test.astype(int)] = 1\n",
    "    \n",
    "    abs_sum = np.abs(y_test_one_hot - y_pred_proba).sum() / y_test.size\n",
    "    abs_sum_scores.append(abs_sum)\n",
    "\n",
    "# 计算平均abs-sum分数\n",
    "average_abs_sum = np.mean(abs_sum_scores)\n",
    "print(f\"Average Abs-Sum Score: {average_abs_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebde3250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting lightgbm\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e1/4c/4685ccfae9806f561de716e32549190c1f533dde5bcadaf83bdf23972cf0/lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91f3084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abs-Sum Score: 0.07831291629137041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 假设 X 和 y 已经准备好了，X 是特征矩阵，y 是目标变量\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "abs_sum_scores = []  # 存储每一折的评分\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # 创建CatBoost模型\n",
    "    model = CatBoostClassifier(loss_function='MultiClass', eval_metric='MultiClass', iterations=1000, learning_rate=0.1, depth=6, verbose=False, random_seed=42)\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=10, use_best_model=True)\n",
    "    \n",
    "    # 预测概率\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # 计算abs-sum\n",
    "    y_test_one_hot = np.zeros((y_test.size, y_pred_proba.shape[1]))\n",
    "    y_test_one_hot[np.arange(y_test.size), y_test.astype(int)] = 1\n",
    "    \n",
    "    abs_sum = np.abs(y_test_one_hot - y_pred_proba).sum() / y_test.size\n",
    "    abs_sum_scores.append(abs_sum)\n",
    "\n",
    "# 计算平均abs-sum分数\n",
    "average_abs_sum = np.mean(abs_sum_scores)\n",
    "print(f\"Average Abs-Sum Score: {average_abs_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "175910b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([64327.,     0.,     0.,  3562.,     0.,     0., 14199.,     0.,\n",
       "            0., 17912.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['label'], orientation = 'vertical', histtype = 'bar', color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1465e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting imblearn\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/92/e8/86c36e1b13007ca9c89381adac6c078cfc8fb71841a76c08a3fe3eca91d3/imbalanced_learn-0.12.0-py3-none-any.whl (257 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.0 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83af88e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Abs-Sum Score: 0.044173902911483334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "abs_sum_scores = []  # 存储每一折的评分\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_resampled, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_resampled, y_test = y[train_index], y[test_index]\n",
    "    # 使用找到的最佳参数设置模型\n",
    "    best_params = {\n",
    "    'colsample_bytree': 0.7692681476866446,\n",
    "    'learning_rate': 0.0823076398078035,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 7,\n",
    "    'n_estimators': 527,\n",
    "    'subsample': 0.848553073033381,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'mlogloss'\n",
    "   }\n",
    "\n",
    "    # 初始化XGBoost模型\n",
    "    model = xgb.XGBClassifier(**best_params)\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 预测概率\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # 计算abs-sum\n",
    "    # 首先，我们需要将y_test转换为one-hot编码形式，以匹配y_pred_proba的格式\n",
    "    y_test_one_hot = np.zeros((y_test.size, y_pred_proba.shape[1]))\n",
    "    y_test_one_hot[np.arange(y_test.size), y_test.astype(int)] = 1\n",
    "    \n",
    "    abs_sum = np.abs(y_test_one_hot - y_pred_proba).sum() / y_test.size\n",
    "    abs_sum_scores.append(abs_sum)\n",
    "\n",
    "# 计算平均abs-sum分数\n",
    "average_abs_sum = np.mean(abs_sum_scores)\n",
    "print(f\"Average Abs-Sum Score: {average_abs_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c033e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
